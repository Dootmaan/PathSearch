# PathSearch
Official Repository for *Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment*

PathSearch is an accurate and scalable system for multimodal pathology retrieval, featuring attentive mosaic mechanism for boosting slide-to-slide retrieval accuracy, while leveraging slide-report alignment to further improve semantic understanding of the slide and enable additional multimodal retrieval support.

**PathSearch shows higher slide-to-slide retrieval accuracy and faster slide encoding & matching speed than existing frameworks, making it suitable for real-world clincal application.**

-----

⚠️ Note: Some files may be missing temporarily and will be added or updated shortly. We will continue to ensure the codes behaving the same as those we used for experimnts.

### 1. Prerequisites

To preprocess the WSIs in a unified style, [EasyMIL Toolbox](https://github.com/birkhoffkiki/EasyMIL) is highly recommended. To process .kfb slides generated by KFBIO scanners in Python easily, please use the [ASlide](https://github.com/MrPeterJin/ASlide) library.

You will need the following libraries to reproduce or deploy PathSearch (Tested on Python 3.9.19):

- torch 2.4.0
- timm 0.9.8 (you will need to switch to a modified version 0.5.4 for CTransPath/CHIEF, which is also provided in EasyMIL)
- einops 0.8.0
- numpy 1.25.1
- scipy 1.13.1
- scikit-learn 1.6.1
- pandas

The full list of the experimental environment will be included in the requirements.txt file. Nonetheless, not all the libraries in that list are required by PathSearch.

### 2. Prepare the data / archive

You can download the TCGA data and corresponding labels from the National Institutes of Health (NIH) genomic data commons (https://portal.gdc.cancer.gov). The Camleyon16 and Camelyon17 datasets are both available at the GrandChallenge platform (https://camelyon16.grand-challenge.org/, https://camelyon17.grand-challenge.org/). The DHMC-LUAD dataset can be  from the Department of Pathology and Laboratory Medicine at Dartmouth-Hitchcock Medical Center and can be accessed through registration and request (https://bmirds.github.io/LungCancer/). You can also prepare your own datasets, as long as you have the whole slide images with you.

You can consistently add different kinds of samples to your searching archive, building you own diagnosis library.

### 3. Clone the code 

Clone the code by running:

```
git clone git@github.com/Dootmaan/PathSearch.git
```

then cd into this directory. 

### 4. Training

Gnenerally speaking, you can directly use the released weights for the attentive mosaic generator and the report encoder in PathSearch framrwork. These weights can be found [here on Zenodo](https://zenodo.org/records/17431804). 

To train PathSearch with the TCGA data pairs, simply run 

```
bash shell/train_pathsearch.sh
```

to train the model from scratch with the default hyper-parameters.

### 5. Testing

This repository has provided four ready-to-run scripts for the four public datasets involved in the study, of which three are external. Simply run 

```
bash shell/test.sh
```

to test the model on these datasets. Of course, you need to specify the path to the archive.

Note: During testing, cache file will be automatically generated to boost future use. You may need to refresh these cache files manually after making modifications to the pipeline.

#### Acknowledgment

We used [CONCH](https://github.com/mahmoodlab/CONCH) for generating patch-level embeddings through EasyMIL. 
We have partially borrowed the code from CLIP and TransMIL to construct PathSearch, and hence PathSearch will also follow a GPL v3 LICENSE upon publication. 
We would like to thank these teams for their dedicated efforts pushing this field forward.